{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from featureEngineering5 import feature_engineering\n",
    "\n",
    "df=pd.read_csv('../data/train.csv', sep=',')\n",
    "df_test=pd.read_csv('../data/test.csv', sep=',')\n",
    "\n",
    "df_d, df_d_test = feature_engineering(df, df_test)\n",
    "\n",
    "features=['Age_', 'Sex_', 'Pclass', 'Fare_', 'Title_s', 'Cabin_s', 'HasFamily', 'Embarked__C', 'Embarked__Q', 'Embarked__S']\n",
    "#features=['Pclass', 'Fare_b','Sex_', 'Age_b', 'Title_s', 'HasFamily']\n",
    "#features=['AgeCat_child', 'AgeCat_aged','AgeCat_adult','AgeCat_senior',\n",
    "#          'Sex_', 'Pclass', 'Fare_b', 'Title_s', 'HasFamily']\n",
    "\n",
    "df_d = df_d[features]\n",
    "df_d_test = df_d_test[features]\n",
    "\n",
    "#####################################################\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X, y = df_d.iloc[:].values, df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feat_labels = df_d.columns\n",
    "X_train = df_d\n",
    "y_train = df['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_d[df_d['IsChild']==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_</th>\n",
       "      <th>Sex_</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare_</th>\n",
       "      <th>Title_s</th>\n",
       "      <th>Cabin_s</th>\n",
       "      <th>HasFamily</th>\n",
       "      <th>Embarked__C</th>\n",
       "      <th>Embarked__Q</th>\n",
       "      <th>Embarked__S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.62500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.64165</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.92500</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.55000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.05000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_  Sex_  Pclass     Fare_  Title_s  Cabin_s  HasFamily  Embarked__C  \\\n",
       "0    22     0       3   3.62500      0.1      0.3          1            0   \n",
       "1    38     1       1  35.64165      0.8      0.6          1            1   \n",
       "2    26     1       3   7.92500      0.9      0.3          0            0   \n",
       "3    35     1       1  26.55000      0.8      0.6          1            0   \n",
       "4    35     0       3   8.05000      0.1      0.3          0            0   \n",
       "\n",
       "   Embarked__Q  Embarked__S  \n",
       "0            0            1  \n",
       "1            0            0  \n",
       "2            0            1  \n",
       "3            0            1  \n",
       "4            0            1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_</th>\n",
       "      <th>Sex_</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare_</th>\n",
       "      <th>Title_s</th>\n",
       "      <th>Cabin_s</th>\n",
       "      <th>HasFamily</th>\n",
       "      <th>Embarked__C</th>\n",
       "      <th>Embarked__Q</th>\n",
       "      <th>Embarked__S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.725219</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>19.916375</td>\n",
       "      <td>0.398092</td>\n",
       "      <td>0.391021</td>\n",
       "      <td>0.397306</td>\n",
       "      <td>0.188552</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.725028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.040965</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>35.841257</td>\n",
       "      <td>0.370888</td>\n",
       "      <td>0.177207</td>\n",
       "      <td>0.489615</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.446751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age_        Sex_      Pclass       Fare_     Title_s     Cabin_s  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    28.725219    0.352413    2.308642   19.916375    0.398092    0.391021   \n",
       "std     14.040965    0.477990    0.836071   35.841257    0.370888    0.177207   \n",
       "min      0.420000    0.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "25%     21.000000    0.000000    2.000000    7.250000    0.100000    0.300000   \n",
       "50%     30.000000    0.000000    3.000000    8.300000    0.100000    0.300000   \n",
       "75%     35.000000    1.000000    3.000000   23.666667    0.800000    0.300000   \n",
       "max     80.000000    1.000000    3.000000  512.329200    1.000000    0.800000   \n",
       "\n",
       "        HasFamily  Embarked__C  Embarked__Q  Embarked__S  \n",
       "count  891.000000   891.000000   891.000000   891.000000  \n",
       "mean     0.397306     0.188552     0.086420     0.725028  \n",
       "std      0.489615     0.391372     0.281141     0.446751  \n",
       "min      0.000000     0.000000     0.000000     0.000000  \n",
       "25%      0.000000     0.000000     0.000000     0.000000  \n",
       "50%      0.000000     0.000000     0.000000     1.000000  \n",
       "75%      1.000000     0.000000     0.000000     1.000000  \n",
       "max      1.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age_           11.0000\n",
       "Sex_            0.0000\n",
       "Pclass          3.0000\n",
       "Fare_           5.8625\n",
       "Title_s         0.8000\n",
       "Cabin_s         0.3000\n",
       "HasFamily       1.0000\n",
       "Embarked__C     0.0000\n",
       "Embarked__Q     0.0000\n",
       "Embarked__S     1.0000\n",
       "Name: 59, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.loc[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X, y = df_d.iloc[:].values, df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "######################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        #('pca', KernelPCA(n_components=8, kernel='rbf', gamma=0.05)),\n",
    "        #('clf', LogisticRegression(random_state=1))\n",
    "        ('clf', KNeighborsClassifier(n_neighbors=5))\n",
    "        #('clf', RandomForestClassifier(n_estimators=100,\n",
    "                                      # criterion='entropy',\n",
    "                                       #random_state=0,\n",
    "                                       #max_depth=4,\n",
    "                                       ##max_features=4,\n",
    "                                       #n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765363128492\n",
      "0.86095505618\n",
      "0.616438356164\n",
      "0.681818181818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "\n",
    "print accuracy_score(pipe.predict(X_test), y_test)\n",
    "print accuracy_score(pipe.predict(X_train), y_train)\n",
    "print precision_score(pipe.predict(X_test), y_test)\n",
    "print f1_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.748 +/- 0.044\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, cross_validation, datasets\n",
    "\n",
    "X, y = df_d.iloc[:].values, df['Survived'].values\n",
    "\n",
    "scores = cross_validation.cross_val_score(pipe, X, y, scoring='f1', cv=8)\n",
    "\n",
    "print('F1: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Tuning hyperparameters via grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        #('pca', KernelPCA(kernel='rbf')),\n",
    "        #('clf', LogisticRegression(random_state=1))\n",
    "        ('clf', KNeighborsClassifier())\n",
    "        #('clf', RandomForestClassifier(n_estimators=100,\n",
    "                                      # criterion='entropy',\n",
    "                                       #random_state=0,\n",
    "                                       #max_depth=4,\n",
    "                                       ##max_features=4,\n",
    "                                       #n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "pca_gamma_range = np.linspace(0.001, 0.1, 10)\n",
    "pca_n_range = range(5,14)\n",
    "knn_n_neighbor_range = range(4,10)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        #'pca__n_components': pca_n_range,\n",
    "        #'pca__gamma': pca_gamma_range,\n",
    "        'clf__n_neighbors': knn_n_neighbor_range\n",
    "    }\n",
    "]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='f1',\n",
    "                  cv=8,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X, y)\n",
    "\n",
    "print gs.best_score_\n",
    "\n",
    "print gs.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_validation.cross_val_score(gs, X, y, scoring='f1', cv=5)\n",
    "print('F1: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        #('pca', KernelPCA(kernel='rbf')),\n",
    "        #('clf', LogisticRegression(random_state=1))\n",
    "        #('clf', KNeighborsClassifier())\n",
    "        #('clf', RandomForestClassifier(n_estimators=100,\n",
    "                                      # criterion='entropy',\n",
    "                                       #random_state=0,\n",
    "                                       #max_depth=4,\n",
    "                                       ##max_features=4,\n",
    "                                       #n_jobs=-1))\n",
    "        ('clf', SVC(kernel='rbf', random_state=2))\n",
    "    ])\n",
    "\n",
    "pca_gamma_range = np.linspace(0.001, 0.1, 10)\n",
    "pca_n_range = range(5,14)\n",
    "\n",
    "clf_C_range = np.linspace(0.1, 100, 3)\n",
    "clf_gamma_range = np.linspace(0.01, 2, 3)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        #'pca__n_components': pca_n_range,\n",
    "        #'pca__gamma': pca_gamma_range,\n",
    "        'clf__C': clf_C_range,\n",
    "        'clf__gamma': clf_gamma_range\n",
    "    }\n",
    "]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='f1',\n",
    "                  cv=8,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print gs.best_score_\n",
    "\n",
    "print gs.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_validation.cross_val_score(gs, X, y, scoring='f1', cv=10)\n",
    "print('F1: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomRorest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.837078651685\n",
      "{'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        #('pca', KernelPCA(kernel='rbf')),\n",
    "        #('clf', LogisticRegression(random_state=1))\n",
    "        #('clf', KNeighborsClassifier())\n",
    "        ('clf', RandomForestClassifier(n_estimators=500,\n",
    "                                       criterion='entropy',\n",
    "                                       random_state=1,\n",
    "                                       #min_samples_split=1, \n",
    "                                       #min_samples_leaf=1,\n",
    "                                       max_features='auto',\n",
    "                                       bootstrap=False,\n",
    "                                       oob_score=False,\n",
    "                                       #max_depth=4,\n",
    "                                      #max_features=4,\n",
    "                                       n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "pca_gamma_range = np.linspace(0.001, 0.1, 5)\n",
    "pca_n_range = range(5,14)\n",
    "\n",
    "#clf_max_features_range = range(3, 5)\n",
    "\n",
    "clf_max_depth_range = range(10, 11)\n",
    "min_samples_leaf_range = range(1, 3)\n",
    "min_samples_split_range = range(8, 10)\n",
    "bootstrap_range = [True]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        #'pca__n_components': pca_n_range,\n",
    "     #'pca__gamma': pca_gamma_range,\n",
    "        'clf__bootstrap': bootstrap_range,\n",
    "     'clf__max_depth': clf_max_depth_range,\n",
    "     #'clf__max_features': clf_max_features_range,\n",
    "        'clf__min_samples_leaf': min_samples_leaf_range,\n",
    "        'clf__min_samples_split' : min_samples_split_range \n",
    "    }\n",
    "]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10,\n",
    "                  #verbose=3,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print gs.best_score_\n",
    "\n",
    "print gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.837078651685\n",
      "{'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 9}\n"
     ]
    }
   ],
   "source": [
    "print gs.best_score_\n",
    "\n",
    "print gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.827 +/- 0.045\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validation.cross_val_score(gs.best_estimator_, X, y, scoring='accuracy', cv=10)\n",
    "print('Acc: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0bd1ecb97808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F1: %.3f +/- %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_validation' is not defined"
     ]
    }
   ],
   "source": [
    "scores = cross_validation.cross_val_score(gs.best_estimator_, X_test, y_test, scoring='f1', cv=2)\n",
    "print('F1: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.87      0.80       106\n",
      "          1       0.75      0.56      0.64        73\n",
      "\n",
      "avg / total       0.74      0.74      0.74       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, gs.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### A try: use simple RandomeRorest to make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from featureEngineering4 import feature_engineering\n",
    "\n",
    "df=pd.read_csv('../data/train.csv', sep=',')\n",
    "df_test=pd.read_csv('../data/test.csv', sep=',')\n",
    "\n",
    "df_d, df_d_test = feature_engineering(df, df_test)\n",
    "\n",
    "features=['IsChild', 'Age_b', 'Sex_', 'Pclass', 'Fare_b', 'Title_s', 'Cabin_s', 'HasFamily', 'Embarked__C', 'Embarked__Q', 'Embarked__S']\n",
    "features=['Pclass', 'Fare_b','Sex_', 'Age_b', 'Title_s', 'HasFamily']\n",
    "features=['Age_b', 'Sex_', 'Pclass', 'Fare_b', 'Title_s', 'HasFamily', 'Embarked__C', 'Embarked__Q', 'Embarked__S']\n",
    "features=['AgeCat_child', 'AgeCat_aged','AgeCat_adult','AgeCat_senior',\n",
    "          'Sex_', 'Pclass', 'Fare_', 'Title_s', 'FamilySize', 'Embarked__C', 'Embarked__Q', 'Embarked__S']\n",
    "\n",
    "\n",
    "df_d = df_d[features]\n",
    "df_d_test = df_d_test[features]\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(\n",
    "                                n_estimators=2000,\n",
    "                                criterion='entropy',\n",
    "                                random_state=1,\n",
    "                                min_samples_split=10, \n",
    "                                min_samples_leaf=1,\n",
    "                                max_features='auto',\n",
    "                                bootstrap=True,\n",
    "                                oob_score=False,\n",
    "                                max_depth=12,\n",
    "                                #max_features=4,\n",
    "                                n_jobs=-1\n",
    "                                )\n",
    "forest.fit(df_d, df['Survived'])\n",
    "\n",
    "df_test['Survived'] = forest.predict(df_d_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df_test['Survived'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv as csv\n",
    "predictions_file = open(\"RandomForest-FE4-max_d=12-special5.csv\", \"wb\")\n",
    "predictions_file_object = csv.writer(predictions_file)\n",
    "predictions_file_object.writerow([\"PassengerId\", \"Survived\"])\t# write the column headers\n",
    "for index, row in df_test.iterrows():\t\t\t\t\t\t\t\t\t# For each row in test file,\n",
    "    predictions_file_object.writerow([row['PassengerId'], row['Survived']])\t\t\t# write the PassengerId, and predict 1\n",
    "predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['Survived'] = gs.best_estimator_.predict(df_d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
