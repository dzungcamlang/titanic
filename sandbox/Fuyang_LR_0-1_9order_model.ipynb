{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "df=pd.read_csv('data/train.csv', sep=',')\n",
    "\n",
    "features = ['Fare_s','Sex_', 'Title_s', 'Pclass_s', 'Age_s','HasAge','Parch_s']\n",
    "#features = ['Sex_', 'Title_s', 'Pclass_s', 'Age_s']\n",
    "#features = ['Sex_', 'Age_s_e']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(C=0.1, random_state=0, n_jobs=-1, class_weight={0: 0.7, 1: 1-0.7})\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(5)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_engineering(_df,title_mapping):\n",
    "    _df['Sex_'] = _df['Sex'].apply(lambda x: 0.1 if x=='female' else 1)\n",
    "    \n",
    "    _df['Fare'] = _df['Fare'].fillna(10)\n",
    "    _df['Fare'] = _df['Fare'].apply(lambda x: 40 if x > 40 else x)\n",
    "    \n",
    "    fareMax = _df['Fare'].max()\n",
    "    fareMin = _df['Fare'].min()\n",
    "\n",
    "    _df['Fare_s'] = (_df['Fare']-fareMin)/(fareMax-fareMin)\n",
    "    \n",
    "    _df['Pclass_s'] = _df['Pclass']/3\n",
    "    \n",
    "    _df['SibSp'] = _df['SibSp'].apply(lambda x: 3 if x > 3 else x)\n",
    "    _df['SibSp_s'] = _df['SibSp']/_df['SibSp'].max()\n",
    "    \n",
    "    _df['Parch'] = _df['Parch'].apply(lambda x: 3 if x > 3 else x)\n",
    "    _df['Parch_s'] = _df['Parch']/_df['Parch'].max()\n",
    "\n",
    "    _df['HasAge'] = _df['Age'].apply(lambda x: 0 if np.isnan(x) else 1)\n",
    "\n",
    "    _df['Age_'] = _df['Age'].fillna(18)\n",
    "    _df['Age_'] = _df['Age_'].apply(lambda x: 1 if x <= 16 else x)\n",
    "    _df['Age_'] = _df['Age_'].apply(lambda x: 22 if x >12 and x <= 29 else x)\n",
    "    _df['Age_'] = _df['Age_'].apply(lambda x: 40 if x >29 and x <= 46 else x)\n",
    "    _df['Age_'] = _df['Age_'].apply(lambda x: 60 if x >46 else x)\n",
    "    ageMax = _df['Age_'].max()\n",
    "    ageMin = _df['Age_'].min()\n",
    "\n",
    "    _df['Age_s'] = (_df['Age_']-ageMin)/(ageMax-ageMin)\n",
    "    \n",
    "    \n",
    "    _df['Age_with_Sex'] = _df['Age_s'] + _df['Sex_']\n",
    "    \n",
    "    _df['Title'] = _df['Name'].apply(lambda x: x.replace('.',',').split(',')[1].strip())\n",
    "    _df['Title_s'] = _df['Title'].map(title_mapping)\n",
    "    _df['Title_s'] = _df['Title_s'].fillna(0);\n",
    "    \n",
    "########################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Capt': 1.0,\n",
       " 'Col': 0.5,\n",
       " 'Don': 1.0,\n",
       " 'Dr': 0.5714285714285714,\n",
       " 'Jonkheer': 1.0,\n",
       " 'Lady': 0.0,\n",
       " 'Major': 0.5,\n",
       " 'Master': 0.42500000000000004,\n",
       " 'Miss': 0.30219780219780223,\n",
       " 'Mlle': 0.0,\n",
       " 'Mme': 0.0,\n",
       " 'Mr': 0.8433268858800773,\n",
       " 'Mrs': 0.20799999999999996,\n",
       " 'Ms': 0.0,\n",
       " 'Rev': 1.0,\n",
       " 'Sir': 0.0,\n",
       " 'the Countess': 0.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title'] = df['Name'].apply(lambda x: x.replace('.',',').split(',')[1].strip())\n",
    "title_mapping={}\n",
    "for t in np.unique(df['Title']):\n",
    "    x = df[df['Title'] == t]\n",
    "    title_mapping[t] = 1 - x['Survived'].sum()/float(len(x['Survived']))\n",
    "\n",
    "\n",
    "feature_engineering(df, title_mapping)\n",
    "\n",
    "title_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random shaffle validation - (don't use this, use the KFold CV below instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def correct_rate(lr_model):\n",
    "    correct_rate = 0.0\n",
    "    correct_rate_train = 0.0\n",
    "\n",
    "    number_run = 10\n",
    "    for i in range(number_run):\n",
    "\n",
    "        msk = np.random.rand(len(df)) < 0.8\n",
    "        _train = df[msk]\n",
    "        _validation = df[~msk]\n",
    "\n",
    "        X_train = _train[features]\n",
    "        X_train = poly.fit_transform(X_train)\n",
    "\n",
    "\n",
    "        lr_model.fit(X_train ,_train['Survived'])\n",
    "\n",
    "        X_validation = _validation[features]\n",
    "        X_validation = poly.fit_transform(X_validation)\n",
    "\n",
    "        #predict = lr_model.predict(X_validation)\n",
    "\n",
    "        #correct_rate += accuracy_score(_validation['Survived'],predict)\n",
    "        correct_rate += lr_model.score(X_validation, _validation['Survived'])\n",
    "        correct_rate_train += lr_model.score(X_train, _train['Survived'])\n",
    "\n",
    "    correct_rate = correct_rate/number_run\n",
    "    correct_rate_train = correct_rate_train/number_run\n",
    "\n",
    "    return (correct_rate, correct_rate_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# correct_rate(lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def correct_rate_KFold(_df, _lr_model,features, label, quiet=False):\n",
    "    # call it as: correct_rate_KFold(df, lr_model, features, 'Survived')\n",
    "    train_data =  poly.fit_transform(_df[features])\n",
    "    kfold = StratifiedKFold(y=_df[label], n_folds=10, random_state=2)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "        _lr_model.fit(train_data[train], _df[label][train])\n",
    "        \n",
    "        #score = _lr_model.score(train_data[test], _df[label][test])\n",
    "        score_t = _lr_model.score(train_data[train], _df[label][train])\n",
    "        \n",
    "        prediction_test = _lr_model.predict(train_data[test])\n",
    "        \n",
    "        score = accuracy_score(y_true=_df[label][test], y_pred=prediction_test)\n",
    "        p = precision_score(y_true=_df[label][test], y_pred=prediction_test)\n",
    "        r = recall_score(y_true=_df[label][test], y_pred=prediction_test)\n",
    "        f1 = f1_score(y_true=_df[label][test], y_pred=prediction_test)\n",
    "        \n",
    "        scores.append((score, score_t, p, r, f1))\n",
    "        if not quiet:\n",
    "            print('Fold: %s, Label dist.: %s, Acc: %.3f, Train_acc: %.3f, P: %.3f, R: %.3f, F1: %.3f' % (k+1,\n",
    "                                                          np.bincount(df[label][train]),\n",
    "                                                          score, score_t, p, r, f1\n",
    "                                                         ))\n",
    "    if not quiet:\n",
    "        r = np.array(scores).mean(0)\n",
    "        print('Total accuracy: %.3f Train_acc: %.3f, P: %.3f, R: %.3f, F1: %.3f' % tuple(r))\n",
    "    return np.mean(np.array(scores),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Label dist.: [494 307], Acc: 0.756, Train_acc: 0.805, P: 0.933, R: 0.400, F1: 0.560\n",
      "Fold: 2, Label dist.: [494 307], Acc: 0.744, Train_acc: 0.797, P: 1.000, R: 0.343, F1: 0.511\n",
      "Fold: 3, Label dist.: [494 308], Acc: 0.742, Train_acc: 0.805, P: 0.824, R: 0.412, F1: 0.549\n",
      "Fold: 4, Label dist.: [494 308], Acc: 0.865, Train_acc: 0.789, P: 0.893, R: 0.735, F1: 0.806\n",
      "Fold: 5, Label dist.: [494 308], Acc: 0.831, Train_acc: 0.792, P: 1.000, R: 0.559, F1: 0.717\n",
      "Fold: 6, Label dist.: [494 308], Acc: 0.809, Train_acc: 0.794, P: 0.947, R: 0.529, F1: 0.679\n",
      "Fold: 7, Label dist.: [494 308], Acc: 0.820, Train_acc: 0.791, P: 1.000, R: 0.529, F1: 0.692\n",
      "Fold: 8, Label dist.: [494 308], Acc: 0.753, Train_acc: 0.803, P: 1.000, R: 0.353, F1: 0.522\n",
      "Fold: 9, Label dist.: [494 308], Acc: 0.820, Train_acc: 0.793, P: 0.950, R: 0.559, F1: 0.704\n",
      "Fold: 10, Label dist.: [495 308], Acc: 0.818, Train_acc: 0.791, P: 0.950, R: 0.559, F1: 0.704\n",
      "Total accuracy: 0.796 Train_acc: 0.796, P: 0.950, R: 0.498, F1: 0.644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.79586313,  0.7959864 ,  0.94970883,  0.49781513,  0.64437902])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_rate_KFold(df, lr_model, features, 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df['Survived'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "_train = df[msk]\n",
    "_validation = df[~msk]\n",
    "\n",
    "X_train = _train[features]\n",
    "X_train = poly.fit_transform(X_train)\n",
    "\n",
    "\n",
    "lr_model.fit(X_train ,_train['Survived'])\n",
    "\n",
    "X_validation = _validation[features]\n",
    "X_validation = poly.fit_transform(X_validation)\n",
    "predict = lr_model.predict(X_validation)\n",
    "\n",
    "confmat = confusion_matrix(y_true=_validation['Survived'], y_pred=predict)\n",
    "\n",
    "print 'One test on a 8/2 split validation data:'\n",
    "print ''\n",
    "print(confmat)\n",
    "\n",
    "print('Accuracy: %.3f' % accuracy_score(y_true=_validation['Survived'], y_pred=predict))\n",
    "print('Precision: %.3f' % precision_score(y_true=_validation['Survived'], y_pred=predict))\n",
    "print('Recall: %.3f' % recall_score(y_true=_validation['Survived'], y_pred=predict))\n",
    "print('F1: %.3f' % f1_score(y_true=_validation['Survived'], y_pred=predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - using cross_validation with f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "threshold = []\n",
    "scores = []\n",
    "for t in np.linspace(0.3, 0.8, num=20):\n",
    "    \n",
    "    lr_model.class_weight = {0:t, 1:1-t}\n",
    "    #f1_s = cross_validation.cross_val_score(lr_model,\n",
    "    #                             poly.fit_transform(df[features]),\n",
    "    #                             df['Survived'],\n",
    "    #                             scoring='f1',\n",
    "    #                             cv=8)\n",
    "    \n",
    "    predicted = cross_validation.cross_val_predict(lr_model, poly.fit_transform(df[features]),\n",
    "                                                   df['Survived'], cv=8, n_jobs=-1)\n",
    "    acc_s = accuracy_score(df['Survived'], predicted)\n",
    "    p_s = precision_score(df['Survived'], predicted)\n",
    "    r_s = recall_score(df['Survived'], predicted)\n",
    "    f1_s = f1_score(df['Survived'], predicted)\n",
    "    \n",
    "    print('Threshold: %.3f, Acc: %.3f, P: %.3f, R: %.3f, F1: %.3f' % (t, acc_s, p_s, r_s, f1_s))\n",
    "    threshold.append(t)\n",
    "    scores.append(np.mean(f1_s))\n",
    "    \n",
    "    #http://stackoverflow.com/questions/19984957/scikit-predict-default-threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Threshold as 0.721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_weight={0: 0.721,\n",
    "              1: 1-0.721}\n",
    "lr_model.class_weight = class_weight\n",
    "print lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good results above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C_para, score = [], []\n",
    "\n",
    "for c in np.arange(-5, 8):\n",
    "    lr = LogisticRegression(C=3**c, random_state=0, n_jobs=-1, class_weight=class_weight)\n",
    "    rate = correct_rate_KFold(df, lr, features, 'Survived', quiet=True)\n",
    "    C_para.append(3**c)\n",
    "    score.append(rate)\n",
    "    \n",
    "    print('C: %f, acc: %.3f' % (3**c, rate[0]))\n",
    "\n",
    "score = np.array(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(C_para, score[:,0], label='validation correct rate')\n",
    "plt.plot(C_para, score[:,1], label='training correct rate')\n",
    "plt.plot(C_para, score[:,2], label='validation precision')\n",
    "plt.plot(C_para, score[:,3], label='validation recall')\n",
    "plt.plot(C_para, score[:,4], label='validation F1')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xscale('log')\n",
    "print lr.class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n=3\n",
    "print C_para[n]\n",
    "print score[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose C=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note, df has already been feature engineered above\n",
    "X = df[features]\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "lr_model_pro = LogisticRegression(C=0.1, random_state=0, n_jobs=-1, class_weight=class_weight)\n",
    "\n",
    "lr_model_pro.fit(X ,df['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre = lr_model_pro.predict(X)\n",
    "print 1 - (pre != df['Survived']).sum()/float(len(df))\n",
    "\n",
    "#alternativly:\n",
    "\n",
    "from sklearn import cross_validation\n",
    "scores = cross_validation.cross_val_score(lr_model_pro,\n",
    "                                 poly.fit_transform(df[features]),\n",
    "                                 df['Survived'],\n",
    "                                 scoring='accuracy',\n",
    "                                 cv=8)\n",
    "print scores.mean()\n",
    "scores = cross_validation.cross_val_score(lr_model_pro,\n",
    "                                 poly.fit_transform(df[features]),\n",
    "                                 df['Survived'],\n",
    "                                 scoring='precision',\n",
    "                                 cv=8)\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(lr_model_pro.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv', sep=',')\n",
    "\n",
    "feature_engineering(test, title_mapping)\n",
    "\n",
    "X_test = test[features]\n",
    "X_test = poly.fit_transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "test['Survived'] = lr_model.predict(X_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(test['Survived'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(test['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv as csv\n",
    "predictions_file = open(\"LRmodel.Od9.C0.1-thre0.721-acc0.79-p0.94.csv\", \"wb\")\n",
    "predictions_file_object = csv.writer(predictions_file)\n",
    "predictions_file_object.writerow([\"PassengerId\", \"Survived\"])\t# write the column headers\n",
    "for index, row in test.iterrows():\t\t\t\t\t\t\t\t\t# For each row in test file,\n",
    "    predictions_file_object.writerow([row['PassengerId'], row['Survived']])\t\t\t# write the PassengerId, and predict 1\n",
    "predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
