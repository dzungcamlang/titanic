{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic - Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "def replace_titles(x):\n",
    "        title=x['Title_']\n",
    "        if title in ['Mr','Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n",
    "            return 'Mr'\n",
    "        elif title in ['Master']:\n",
    "            return 'Master'\n",
    "        elif title in ['Countess', 'Mme','Mrs']:\n",
    "            return 'Mrs'\n",
    "        elif title in ['Mlle', 'Ms','Miss']:\n",
    "            return 'Miss'\n",
    "        elif title =='Dr':\n",
    "            if x['Sex']=='Male':\n",
    "                return 'Mr'\n",
    "            else:\n",
    "                return 'Mrs'\n",
    "        elif title =='':\n",
    "            if x['Sex']=='Male':\n",
    "                return 'Master'\n",
    "            else:\n",
    "                return 'Miss'\n",
    "        else:\n",
    "            return title\n",
    "\n",
    "def feature_engineering(_df, get_dummies=False):\n",
    "\n",
    "    imputer_age = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "\n",
    "    imputer_age.fit(_df[['Age']])\n",
    "\n",
    "    # Title:\n",
    "    _df['Title_'] = _df['Name'].apply(lambda x: x.replace('.',',').split(',')[1].strip())\n",
    "    _df['Title_'] = _df.apply(replace_titles, axis=1)\n",
    "\n",
    "    # Fare:\n",
    "    # fill NaN\n",
    "    _df['Fare_'] = _df['Fare']\n",
    "    _df.loc[ (_df.Fare.isnull())&(_df.Pclass==1),'Fare_'] =np.median(_df[_df['Pclass'] == 1]['Fare'].dropna())\n",
    "    _df.loc[ (_df.Fare.isnull())&(_df.Pclass==2),'Fare_'] =np.median( _df[_df['Pclass'] == 2]['Fare'].dropna())\n",
    "    _df.loc[ (_df.Fare.isnull())&(_df.Pclass==3),'Fare_'] = np.median(_df[_df['Pclass'] == 3]['Fare'].dropna())\n",
    "    #\n",
    "    _df['Fare_'] = _df['Fare_'] / (1+_df['SibSp']+_df['Parch'])\n",
    "    _df['Fare_'] = _df['Fare_'].apply(lambda x: 40 if x > 40 else x)\n",
    "    \n",
    "    # SibSp and Parch:\n",
    "    _df['SibSp_'] = _df['SibSp'].apply(lambda x: 3 if x > 3 else x)\n",
    "    _df['Parch_'] = _df['Parch'].apply(lambda x: 3 if x > 3 else x)\n",
    "    _df['FamilySize_'] = _df['SibSp_'] + _df['Parch_'];\n",
    "\n",
    "    # Age\n",
    "    _df['HasAge'] = _df['Age'].apply(lambda x: 0 if np.isnan(x) else 1)\n",
    "    _df['Age_'] = imputer_age.transform(_df['Age'].reshape(-1, 1))\n",
    "    # or\n",
    "    #_df['Age_'] = _df[\"Age\"].fillna(_df[\"Age\"].mean())\n",
    "    # http://stackoverflow.com/questions/21050426/pandas-impute-nans\n",
    "\n",
    "    _df['Age_b'] = np.digitize(_df['Age_'], [0,5,10,15,20,25,28,30,35,40,45,50,55,60,65,70])\n",
    "\n",
    "    # Cabin:\n",
    "    _df['Cabin_'] = _df['Cabin'].apply(lambda x: 'X' if isinstance(x, float) else x[0])\n",
    "    # NaN is no problem for get_dummies\n",
    "    # However let's try to keep it as a feature called X\n",
    "\n",
    "    # Embarked:\n",
    "    _df['Embarked_'] = _df['Embarked'].apply(lambda x: 'S' if isinstance(x, float) else x)\n",
    "\n",
    "    df_return = _df[['Age_','Age_b','HasAge','Sex','Pclass',\n",
    "                     'Fare_','Title_','SibSp_', 'Parch_', \n",
    "                     'FamilySize_','Embarked_','Cabin_']]\n",
    "\n",
    "    if get_dummies:\n",
    "        return pd.get_dummies(df_return) # Onehot encoding\n",
    "    else:\n",
    "        return df_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "df=pd.read_csv('data/train.csv', sep=',')\n",
    "df_test=pd.read_csv('data/test.csv', sep=',')\n",
    "\n",
    "df_d = feature_engineering(df, get_dummies=True)\n",
    "df_d_test = feature_engineering(df_test, get_dummies=True)\n",
    "\n",
    "features=[\n",
    "          'Age_b', 'HasAge', 'Sex_female', 'Sex_male', 'Pclass', 'Fare_',\n",
    "          'Title__Mr', 'Title__Master','Title__Mrs','Title__Miss', 'FamilySize_',\n",
    "          'Embarked__C', 'Embarked__Q', 'Embarked__S'\n",
    "         ]\n",
    "\n",
    "df_d = df_d[features]\n",
    "df_d_test = df_d_test[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_b</th>\n",
       "      <th>HasAge</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare_</th>\n",
       "      <th>Title__Mr</th>\n",
       "      <th>Title__Master</th>\n",
       "      <th>Title__Mrs</th>\n",
       "      <th>Title__Miss</th>\n",
       "      <th>FamilySize_</th>\n",
       "      <th>Embarked__C</th>\n",
       "      <th>Embarked__Q</th>\n",
       "      <th>Embarked__S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.62500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.64165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.92500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.55000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.05000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_b  HasAge  Sex_female  Sex_male  Pclass     Fare_  Title__Mr  \\\n",
       "0      5       1           0         1       3   3.62500          1   \n",
       "1      9       1           1         0       1  35.64165          0   \n",
       "2      6       1           1         0       3   7.92500          0   \n",
       "3      9       1           1         0       1  26.55000          0   \n",
       "4      9       1           0         1       3   8.05000          1   \n",
       "\n",
       "   Title__Master  Title__Mrs  Title__Miss  FamilySize_  Embarked__C  \\\n",
       "0              0           0            0            1            0   \n",
       "1              0           1            0            1            1   \n",
       "2              0           0            1            0            0   \n",
       "3              0           1            0            1            0   \n",
       "4              0           0            0            0            0   \n",
       "\n",
       "   Embarked__Q  Embarked__S  \n",
       "0            0            1  \n",
       "1            0            0  \n",
       "2            0            1  \n",
       "3            0            1  \n",
       "4            0            1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X, y = df_d.iloc[:].values, df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model only on the Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV \n",
    "\n",
    "* Note, it might take a long time to solve with grid search. Try reduce the parameter ranges for searching if you wish to finish running it faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752087498999\n",
      "{'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([\n",
    "        #('scaler', StandardScaler()),\n",
    "        #('pca', KernelPCA(kernel='rbf')),\n",
    "        #('clf', LogisticRegression(random_state=1))\n",
    "        #('clf', KNeighborsClassifier())\n",
    "        ('clf', RandomForestClassifier(n_estimators=1000,\n",
    "                                       criterion='entropy',\n",
    "                                       random_state=1,\n",
    "                                       #min_samples_split=1, \n",
    "                                       #min_samples_leaf=1,\n",
    "                                       max_features='auto',\n",
    "                                       bootstrap=False,\n",
    "                                       oob_score=False,\n",
    "                                       #max_depth=4,\n",
    "                                       #max_features=4,\n",
    "                                       n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "\n",
    "bootstrap_range = [True]\n",
    "clf_max_depth_range = range(9, 12)\n",
    "min_samples_leaf_range = range(1, 2)\n",
    "min_samples_split_range = range(9, 12)\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'clf__bootstrap': bootstrap_range,\n",
    "        'clf__max_depth': clf_max_depth_range,\n",
    "        'clf__min_samples_leaf': min_samples_leaf_range,\n",
    "        'clf__min_samples_split' : min_samples_split_range \n",
    "    }\n",
    "]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='f1',\n",
    "                  cv=10,\n",
    "                  #verbose=3,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print gs.best_score_\n",
    "\n",
    "print gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "gs.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.890\n",
      "Training Precision: 0.793\n",
      "Training Recall: 0.907\n",
      "Training F1: 0.846\n"
     ]
    }
   ],
   "source": [
    "print( 'Training Acc: %.3f' % accuracy_score(gs.predict(X_train), y_train))\n",
    "print( 'Training Precision: %.3f' % precision_score(gs.predict(X_train), y_train))\n",
    "print( 'Training Recall: %.3f' % recall_score(gs.predict(X_train), y_train))\n",
    "print( 'Training F1: %.3f' % f1_score(gs.predict(X_train), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.866\n",
      "Test Precision: 0.750\n",
      "Test Recall: 0.900\n",
      "Test F1: 0.818\n"
     ]
    }
   ],
   "source": [
    "print( 'Test Acc: %.3f' % accuracy_score(gs.predict(X_test), y_test))\n",
    "print( 'Test Precision: %.3f' % precision_score(gs.predict(X_test), y_test))\n",
    "print( 'Test Recall: %.3f' % recall_score(gs.predict(X_test), y_test))\n",
    "print( 'Test F1: %.3f' % f1_score(gs.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.94      0.89       107\n",
      "          1       0.90      0.75      0.82        72\n",
      "\n",
      "avg / total       0.87      0.87      0.86       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, gs.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested CrossValidation to give a better score evaluation on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation check for Acc: 0.834 +/- 0.044\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validation.cross_val_score(gs.best_estimator_, X, y, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "print('Cross validation check for Acc: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation check for F1: 0.766 +/- 0.073\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validation.cross_val_score(gs.best_estimator_, X, y, scoring='f1', cv=10, n_jobs=-1)\n",
    "print('Cross validation check for F1: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model with all training data and do prediction on Kaggle test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = gs.best_estimator_\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 268.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,  150.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA6mVHW9hQsvVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f6509d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test['Survived'] = clf.predict(df_d_test)\n",
    "plt.hist(df_test['Survived'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save result in file for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv as csv\n",
    "predictions_file = open(\"Demo1.csv\", \"wb\")\n",
    "predictions_file_object = csv.writer(predictions_file)\n",
    "predictions_file_object.writerow([\"PassengerId\", \"Survived\"]) # write the column headers\n",
    "for index, row in df_test.iterrows():  # For each row in test file\n",
    "    predictions_file_object.writerow([row['PassengerId'], row['Survived']]) # write the PassengerId, and predict 1\n",
    "predictions_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "By submitting the result csv to Kaggle, we get a score on Leaderboard of 0.76555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
